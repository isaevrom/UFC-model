{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "314dc81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_per_page = list()\n",
    "\n",
    "for i in range(1,25):\n",
    "    with open(f\"urls/page_{i}\", 'r') as page:\n",
    "        urls_per_page.append(page.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ac8cf017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_winner_name(page) -> str:\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "    try:\n",
    "        results = soup.find(\"i\", class_=\"b-fight-details__person-status b-fight-details__person-status_style_green\").parent()\n",
    "    except:\n",
    "        return \"Draw\"\n",
    "    for result in results:\n",
    "        # print(result)\n",
    "        # print('\\n')\n",
    "\n",
    "        if result.find(\"a\", class_=\"b-link b-fight-details__person-link\") != None:\n",
    "            # print(\"#\" + result.find(\"a\", class_=\"b-link b-fight-details__person-link\").text.strip() + \"#\")\n",
    "            winner_name = result.find(\"a\", class_=\"b-link b-fight-details__person-link\").text.strip()\n",
    "            break\n",
    "    print(f\"Winner: {winner_name}\")\n",
    "    return winner_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "459670e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_exists(file_path):\n",
    "    import os.path\n",
    "    return os.path.isfile(file_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "1fab35bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_1 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_2 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_3 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_4 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_5 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_6 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_7 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_8 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_9 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_10 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_11 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_12 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_13 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_14 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_15 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_16 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_17 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_18 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_19 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_20 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_21 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_22 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_23 ALREADY EXISTS!\n",
      "\n",
      "\n",
      "page_24 ALREADY EXISTS!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests as rq\n",
    "import pandas as pd\n",
    "\n",
    "for i, urls in enumerate(urls_per_page):\n",
    "    csv_name = f'tables/page_{i+1}'\n",
    "    if file_exists(csv_name):\n",
    "        print(f'page_{i+1} ALREADY EXISTS!\\n\\n')\n",
    "        continue\n",
    "    page_df = pd.DataFrame()\n",
    "    for url in urls:\n",
    "        url  = url.strip('\\n')\n",
    "        page = rq.get(url)\n",
    "        winner = get_winner_name(page)\n",
    "        if winner == \"Draw\":\n",
    "            continue\n",
    "        dfs = pd.read_html(page.text)\n",
    "        df  = pd.concat([dfs[0], dfs[2]], axis=1)\n",
    "        '''\n",
    "        UFC page contains sort of an error - there are two tables\n",
    "        one of them has column name 'Sig. str.' and the other 'Sig. str'\n",
    "        thus I just strip dot signs at the end of columns to avoid any duplicities of that kind\n",
    "        '''\n",
    "        df.columns = [col.strip('.') for col in df.columns]\n",
    "        df = df.loc[:, ~df.columns.duplicated(keep='first')]\n",
    "        df['Winner'] = winner\n",
    "        page_df = pd.concat([page_df, df], axis=0)\n",
    "    page_df.to_csv(csv_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
